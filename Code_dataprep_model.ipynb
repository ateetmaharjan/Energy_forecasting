{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT REQUIRED LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import openpyxl\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "import plotly.graph_objects as go      # pip install plotly, conda install -c plotly plotly=4.8.1\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "import plotly.offline as py\n",
    "from plotly.offline import init_notebook_mode, plot_mpl\n",
    "from fbprophet.plot import plot_plotly # pip install fbprophet\n",
    "from fbprophet import Prophet\n",
    "import pandas as pd\n",
    "py.init_notebook_mode()\n",
    "pd.options.plotting.backend = 'plotly'  # change default pandas matplotlib to plotly\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#pretty cell outputs: runs all codes in each cell\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import csv file\n",
    "rawdf = pd.read_csv('./data/01_rawdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdf.shape\n",
    "rawdf.head()\n",
    "# rawdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for null values\n",
    "# rawdf.isna().sum()\n",
    "# rawdf = rawdf.dropna() # to get rid of null values\n",
    "# rawdf.shape\n",
    "# # get rid of empty values\n",
    "# rawdf.dropna(axis=1,how='all',inplace=True)\n",
    "# rawdf.dropna(axis=0,how='all',inplace=True)\n",
    "# rawdf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA MANIPULATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert date column to datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to datetime format\n",
    "rawdf['date'] = pd.to_datetime(rawdf['date'])\n",
    "\n",
    "# convert date as string and split date and time and keep only date\n",
    "# rawdf.date = rawdf.date.apply(str).str.split(' ').str[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stack hour column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacking all hours into date time stamp making univariate dataset\n",
    "rawdf = pd.melt(\n",
    "    rawdf,\n",
    "    id_vars=['date', 'zone_id'],\n",
    "    value_vars=['h_0', 'h_1', 'h_2', 'h_3', 'h_4', 'h_5', 'h_6',\n",
    "                'h_7', 'h_8', 'h_9', 'h_10', 'h_11', 'h_12', 'h_13', 'h_14', 'h_15',\n",
    "                'h_16', 'h_17', 'h_18', 'h_19', 'h_20', 'h_21', 'h_22', 'h_23'],\n",
    "    var_name='hour',\n",
    "    value_name='load_value')\n",
    "\n",
    "# remove h_ from hour values\n",
    "rawdf.hour = rawdf.hour.str.strip('h_')\n",
    "rawdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join date and hour and convert to datetime format and unstack zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert date as string and split date and time and keep only date\n",
    "# rawdf['ds'] = rawdf.ds.apply(str).str.split(' ').str[0]\n",
    "\n",
    "rawdf['date'] = pd.to_datetime(\n",
    "    rawdf.date, errors='coerce') + rawdf.hour.astype('timedelta64[h]')\n",
    "rawdf.date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdf = rawdf.drop(columns=['hour'])\n",
    "rawdf.zone_id = rawdf.zone_id.astype('category')  # to reduce size of dataframe\n",
    "rawdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep zones as columns\n",
    "rawdf = rawdf.pivot_table(\n",
    "    values='load_value',\n",
    "    index='date',\n",
    "    columns='zone_id',\n",
    "    dropna=False\n",
    ")\n",
    "# list comprehension method to add prefix zone_ in columns\n",
    "rawdf.columns = ['zone_' + str(col) for col in rawdf.columns]\n",
    "rawdf.head(2).append(rawdf.tail(2))\n",
    "rawdf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VISUALIZATION\n",
    "## Let’s plot hourly data for each column of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set notebook mode to work in offline\n",
    "py.init_notebook_mode()\n",
    "\n",
    "fig=rawdf.iloc[:,0:1].plot(template=\"ggplot2\")    # change pandas backend to plotly to replace matplotlib\n",
    "fig = fig.update_layout(\n",
    "    yaxis_title=\"<b>Load value (in kW)</b>\",\n",
    "    title=\"<b>Energy load demand </b>\",\n",
    "    title_x=0.5, \n",
    "    xaxis_title= \"<b>Date</b>\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESAMPLING \n",
    "## Convert to daily data if modeling is done on daily rather than hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take daily data\n",
    "rawdf_day = rawdf.resample('D').sum()\n",
    "rawdf_day.head(2).append(rawdf_day.tail(2))\n",
    "rawdf_day.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdf_day.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot shows seasonality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Take subset of dataframe choosing daily data for 5 zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets use only 5 zones\n",
    "# data = rawdf.iloc[:, 0:5]           # hourly data\n",
    "data = rawdf_day.iloc[:, 0:5]       # daily data\n",
    "data.head(2).append(data.tail(2))\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series plot for zone 1 (daily data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set notebook mode to work in offline\n",
    "py.init_notebook_mode()\n",
    "\n",
    "# create output directory\n",
    "\n",
    "if not os.path.exists(\"images\"):\n",
    "    os.mkdir(\"images\")\n",
    "# define a function to plot graph\n",
    "\n",
    "def plot_tsplot(col):\n",
    "    fig = go.Figure()\n",
    "    fig = fig.add_trace(go.Scatter(\n",
    "        x=data.index, y=data[col], mode='lines'))  # mode='lines+markers'\n",
    "    fig = fig.update_layout(\n",
    "        width = 1000, height = 600,\n",
    "        title=dict(text=\"<b>Timeseries plot for daily demand for energy for \"+col+\"</b>\",\n",
    "                   y=0.9, x=0.5, font_size=18),\n",
    "        # hovermode='x',\n",
    "        xaxis=dict(\n",
    "            title=\"<b>Date</b>\", linecolor='black', linewidth=1,\n",
    "            rangeslider_visible=True,\n",
    "            rangeselector=dict(\n",
    "                buttons=list(\n",
    "                    [dict(count=7, label=\"1w\", step=\"day\", stepmode=\"backward\"),\n",
    "                     dict(count=1, label=\"1m\", step=\"month\", stepmode=\"backward\"),\n",
    "                     dict(count=6, label=\"6m\", step=\"month\", stepmode=\"backward\"),\n",
    "                     dict(count=1, label=\"1y\", step=\"year\", stepmode=\"backward\"),\n",
    "                     dict(label='full', step=\"all\")\n",
    "                     ])\n",
    "            ),\n",
    "            ticks=\"outside\"\n",
    "        ),\n",
    "        yaxis=dict(title=\"<b>Load demand (in kW)</b>\",\n",
    "                   linecolor='black', linewidth=1,  ticks=\"outside\"),\n",
    "        font=dict(family=\"Helvetica\", size=12, color=\"black\"),\n",
    "        paper_bgcolor=\"white\",\n",
    "        template=\"plotly\",\n",
    "        # width=600, height=400\n",
    "        # legend=dict(\n",
    "        #     title=\"Type\", orientation=\"h\", x=0.25, y=-0.6,\n",
    "        #     bgcolor=\"blue\", bordercolor=\"black\", borderwidth=1\n",
    "        # )\n",
    "    )\n",
    "    fig.write_html(\"images/\"+col+\"_EDA_tstplot\"\".html\")       # write_image for other formats\n",
    "    fig.show()\n",
    "\n",
    "# display for only 1 plot, change as required\n",
    "for col in data.columns[0:1]:\n",
    "    plot_tsplot(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot method 2: with backend plotly and using ggplot2 theme\n",
    "\n",
    "# for colnum in range(0, 5):\n",
    "#     data.iloc[:, colnum].plot(template=\"ggplot2\").show()\n",
    "\n",
    "# fig.update_layout(\n",
    "#     yaxis_title=\"<b>Load value (in kW)</b>\",\n",
    "#     title=\"<b>Energy load demand </b>\",\n",
    "#     title_x=0.5, \n",
    "#     xaxis_title= \"<b>Date</b>\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## EXPORT CSV FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export as csv file with 5 zones\n",
    "\n",
    "data.to_csv(\"./data/02_clean_data.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO RUN LOOP FOR ALL DATAFRAME and columns, DO STH LIKE THIS\n",
    "\n",
    "# def eachzone(col):\n",
    "#     # ALL YOUR ACTIONS\n",
    "#     print(data.columns)\n",
    "\n",
    "# for col in data:\n",
    "#     eachzone(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELING USING FBPROPHET\n",
    "## Creating the data set for Prophet\n",
    "The ds column should be YYYY-MM-DD for a date, or YYYY-MM-DD HH:MM:SS for a timestamp. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import holidays csv file\n",
    "holidays = pd.read_csv('./data/holidays.csv')\n",
    "holidays.ds=pd.to_datetime(holidays.ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter by each zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.columns\n",
    "# ['zone_1', 'zone_2', 'zone_3', 'zone_4', 'zone_5']\n",
    "col = 'zone_1'\n",
    "df = data[[col]].reset_index()  # select each zone and reset index\n",
    "# Prophet requires date = ds, feature = y\n",
    "df.columns = ['ds', 'y']\n",
    "df.head(2).append(df.tail(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Split data into training and test set (80-20)\n",
    "\n",
    "First 80% of data are taken as training and remaining 20% as test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # split data into training and validation set\n",
    "training_size = int(len(df)*0.8)\n",
    "print(training_size)\n",
    "\n",
    "train_df, test_df = df[: training_size], df[training_size:]\n",
    "print(len(train_df)*100/(len(train_df)+len(test_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Fit Prophet Model\n",
    "\n",
    "Prophet will by default fit weekly and yearly seasonalities if the time series is more than two cycles long. It will also fit daily seasonality for a sub-daily time series. You can add other seasonalities (monthly, quarterly, hourly)if required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit basic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # fit a prophet model on training dataset\n",
    "\n",
    "# model = Prophet()        \n",
    "# model.fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check forecasting errors from basic model and retweak parameters in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check EDA for monthly and quarterly trend or other and add seasonality based on that\n",
    "# Do not run loop randomly for optimizing model\n",
    "# HOliday --do not use for hourly data, holidays_prior_scale = 20-40, try big if holidays have high impact, default=10\n",
    "# growth = linear default, if curve then logistic, \n",
    "# fourier: try 10-25 (higher normally gives better result)\n",
    "# period = 30.5 --> what happened at a certain point is likely to happen again in 35 days.\n",
    "# seasonality_prior_scale: 10-25\n",
    "# n_changepoints: sudden/abrupt change in trend, let prophet find itself and then add.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Prophet(\n",
    "    growth='linear',\n",
    "#     holidays=holidays,           \n",
    "    seasonality_mode='additive',\n",
    "#     n_changepoints = 100,          # default = 25 \n",
    "    changepoint_prior_scale=0.05, # default = 0.05\n",
    "#     seasonality_prior_scale=15,\n",
    "#     holidays_prior_scale=10,      # default = 10\n",
    "    daily_seasonality=False,\n",
    "    weekly_seasonality=False,\n",
    "    yearly_seasonality=False\n",
    "#     ).add_seasonality(name=\"monthly\", period=30.5, fourier_order=6\n",
    "    # ).add_seasonality(name=\"daily\", period=1,fourier_order=15\n",
    "    ).add_seasonality(name=\"weekly\", period=7,fourier_order=3\n",
    "#     ).add_seasonality(name=\"6month\", period=30.5*6,fourier_order=4\n",
    "    ).add_seasonality(name=\"yearly\", period=365.25,fourier_order=10\n",
    "    # ).add_seasonality(name=\"quarterly\", period=365.25/4, fourier_order=5, prior_scale=15\n",
    "    )\n",
    "model.fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the values for the future\n",
    "\n",
    "Create a dataframe with ds(datetime stamp) containing the dates for which we want to make the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dataframe including test size, By default it includes dates from the history\n",
    "# specify frequency as H if hourly and D if daily data\n",
    "future = model.make_future_dataframe(periods=len(test_df), freq='D') # periods=300, freq='H', 'month'\n",
    "\n",
    "# Predict for train/test dataset\n",
    "forecast = model.predict(future)\n",
    "# forecast1.tail().T # transpose dataframe\n",
    "# forecast[(forecast.ds > \"2008-6-22\")].head().T\n",
    "forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Create a full dataframe matching the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a funtion to create dataframe containing prediction and actual values\n",
    "def actual_pred_dataframe(historical, forecast):\n",
    "    return forecast.set_index('ds')[\n",
    "        ['yhat', 'yhat_lower', 'yhat_upper']].join(historical.set_index('ds'))\n",
    "\n",
    "cmp_df = actual_pred_dataframe(df, forecast)\n",
    "cmp_df.head(2).append(cmp_df.tail(2))\n",
    "cmp_df.to_csv(\"./data/03_cmp_df.csv\", index=True)        # Export as csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate performance of model using MAPE and MAE\n",
    "MAPE: mean absolute percentage error <Br>\n",
    "MAE: mean absolute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to calculate MAPE and MAE\n",
    "\n",
    "def calculate_forecast_errors(dataframe, training_size):\n",
    "    dataframe = dataframe.copy()\n",
    "\n",
    "    dataframe['e'] = dataframe['y'] - dataframe['yhat']\n",
    "    dataframe['p'] = 100 * dataframe['e'] / dataframe['y']\n",
    "\n",
    "    predicted_part = dataframe[training_size:]              # test data part\n",
    "\n",
    "    def error_mean(error_name):\n",
    "        return np.mean(abs(predicted_part[error_name])).round(2)\n",
    "\n",
    "    return {'MAPE': error_mean('p'), 'MAE': error_mean('e')}\n",
    "\n",
    "# Print MAPE and MAE\n",
    "\n",
    "for error_name, err_value in calculate_forecast_errors(cmp_df, training_size).items():\n",
    "    print(error_name, err_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation of errors\n",
    "- Basic model: \n",
    "MAPE 11.4;\n",
    "MAE  187042.95\n",
    "\n",
    "- Tweaked model:\n",
    "MAPE 11.38;\n",
    "    MAE  186657.72 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets choose model with tweaked parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # CREATE VISUALIZATIONS\n",
    "\n",
    " ## Component plot (training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display forecast components Prophet.plot_components method\n",
    "# trend, yearly seasonality, and weekly seasonality of the time series\n",
    "# include holiday to see holidays\n",
    "\n",
    "component_plot = model.plot_components(forecast)\n",
    "component_plot.savefig(\"images/\"+col+\"_component_plot_train\"\".pdf\")  # pandas---savefig, write_html\n",
    "\n",
    "# py.init_notebook_mode(connected=True)   # connection=false,default,requires internet, file size high\n",
    "# convert the plot into interactive one\n",
    "# component_plot = plot_mpl(component_plot, filename=\"images/component_plot_train.html\", auto_open=True)        #opens graph in html in brower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations from component plot for zone 1\n",
    "- Increased trend was observed in 2005. After which trend is going down. It was during **`the great recession`**, a global economic downturn that devastated word financial markets as well as the banking and real estate industries.\n",
    "- Weekly trend shows higher demand on monday, tuesday and saturday\n",
    "- Yearly trend shows higher demand during January-February (winter season) and July-August (summer season).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual vs predicted plot (train dataset with prediction for test dataset-date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py.init_notebook_mode()              # make it true if you want reduce file, but you need to be online\n",
    "forecast_plot = plot_plotly(model, forecast)  # This returns a plotly Figure\n",
    "forecast_plot.write_html(\"images/forecast_plot_traintest.html\", auto_open=False) # turn it to true if you want to open it on own.show\n",
    "forecast_plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative graph: Training and Test Dataset with prediction by model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set notebook mode to work in offline\n",
    "py.init_notebook_mode()\n",
    "\n",
    "fig = go.Figure()\n",
    "fig = fig.add_trace(go.Scatter(\n",
    "    x=cmp_df.index, y=cmp_df.y, mode='markers', name='actual',line_color='rgb(0,100,80)'))\n",
    "fig = fig.add_trace(go.Scatter(\n",
    "    x=cmp_df.index, y=cmp_df.yhat, mode='lines', name='predicted', line_color='rgb(231,107,243)'))\n",
    "fig = fig.update_layout(\n",
    "    width=1000, height=600,\n",
    "    title=dict(text=\"<b>Prophet model train test</b>\", y=0.9, x=0.5, font_size=18),\n",
    "    xaxis=dict(title=\"<b>Date</b>\", linecolor='black', linewidth=1,\n",
    "        rangeselector=dict(\n",
    "            buttons=list(\n",
    "                [dict(count=7, label=\"1w\", step=\"day\",\n",
    "                        stepmode=\"backward\"),\n",
    "                    dict(count=1, label=\"1m\", step=\"month\",\n",
    "                        stepmode=\"backward\"),\n",
    "                    dict(count=6, label=\"6m\", step=\"month\",\n",
    "                        stepmode=\"backward\"),\n",
    "                    dict(count=1, label=\"1y\", step=\"year\",\n",
    "                        stepmode=\"backward\"),\n",
    "                    dict(label='full', step=\"all\")\n",
    "                    ])\n",
    "    )),\n",
    "    yaxis=dict(title=\"<b>Load demand (in kW)</b>\", linecolor='black', linewidth=1),\n",
    "    font=dict(family=\"Helvetica\", size=12, color=\"black\"),\n",
    "    paper_bgcolor=\"white\"\n",
    "    )\n",
    "\n",
    "fig = fig.add_shape(\n",
    "        # filled Rectangle\n",
    "            type=\"rect\",\n",
    "            x0=\"2007-08-01\", y0=0,\n",
    "            x1=\"2008-06-22\", y1=3000000,\n",
    "            line=dict(\n",
    "                color=\"black\",\n",
    "                width=1,\n",
    "            ),\n",
    "            fillcolor=\"red\", opacity=0.09, layer=\"below\", line_width=0\n",
    "        )\n",
    "\n",
    "fig.write_html(\"images/\"+col+\"_Train_Test_actualvspred\"\".html\")       # write_image for other formats\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative way to get forecasting errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_forecast = forecast[training_size:]\n",
    "\n",
    "# from math import sqrt\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# def mean_absolute_percentage_error(y_true, y_pred):\n",
    "#     return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "# def errors(y_true,y_pred):\n",
    "#     rmse = sqrt(mean_squared_error(y_true, y_pred))\n",
    "#     mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "#     return{'MAPE':mape,\n",
    "#            'RMSE':rmse}\n",
    "\n",
    "# errors(test_df.y, test_forecast.yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # RETAIN MODEL AND FIT TO FULL DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fit prophet model with similar parameters on full dataset\n",
    "model2 = Prophet(\n",
    "    growth='linear',       \n",
    "    seasonality_mode='additive',\n",
    "    changepoint_prior_scale=0.05, # default = 0.05\n",
    "    daily_seasonality=False,\n",
    "    weekly_seasonality=False,\n",
    "    yearly_seasonality=False\n",
    "    ).add_seasonality(name=\"weekly\", period=7,fourier_order=3\n",
    "    ).add_seasonality(name=\"yearly\", period=365.25,fourier_order=10\n",
    "    )\n",
    "model2.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future2 = model2.make_future_dataframe(periods=30, freq='D') # 24*7 days for hourly data\n",
    "\n",
    "# Predict for train/test dataset\n",
    "forecast2 = model2.predict(future2)\n",
    "\n",
    "# forecast2[(forecast2.ds > \"2008-6-23\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataframe for forecast period only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just the forecasted part not the whole dataset\n",
    "final_forecast = forecast2.set_index('ds')\n",
    "final_forecast = final_forecast[['yhat', 'yhat_lower', 'yhat_upper']].tail(30)\n",
    "final_forecast.to_csv(\"./data/04_final_forecast.csv\", index=True)        # Export as csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # CREATE FINAL VISUALIZATIONS: \n",
    " ## Actual vs predicted for train,test along with future prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp_df.head(2).append(cmp_df.tail(2))                   # cmp_df: full dataset with actual and prediction\n",
    "final_forecast.head(2).append(final_forecast.tail(2))   # final_forecast: future predicted dataset y-hat and confidence interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create upper and lower limit values for forecast in plotting a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for final_forecast upper and lower limit\n",
    "x3 = final_forecast.index\n",
    "x3_rev = x3[::-1]  # make reverse\n",
    "\n",
    "y3 = final_forecast.yhat\n",
    "y3_upper = final_forecast.yhat_upper\n",
    "y3_lower = final_forecast.yhat_lower\n",
    "y3_lower = y3_lower[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast plot (final dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set notebook mode to work in offline\n",
    "py.init_notebook_mode()\n",
    "\n",
    "# create figure\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add line 1\n",
    "fig = fig.add_trace(go.Scatter(\n",
    "    x=cmp_df.index, y=cmp_df.y, mode='lines', name='actual', line_color='rgb(0,100,80)'))\n",
    "# Add line 2\n",
    "fig = fig.add_trace(go.Scatter(\n",
    "    x=cmp_df.index, y=cmp_df.yhat, mode='lines', name='predicted', line_color='rgb(231,107,243)'))\n",
    "\n",
    "\n",
    "# Add lower and upper limit area for line 3\n",
    "fig = fig.add_trace(go.Scatter(\n",
    "    x=x3.append(x3_rev),  # are dataframe, so append\n",
    "    y=y3_upper.append(y3_lower),\n",
    "    fill='toself', fillcolor='rgba(0,176,246,0.2)', line_color='rgba(255,255,255,0)',\n",
    "    name='future_prediction', showlegend=False))\n",
    "# Add line 3\n",
    "fig = fig.add_trace(go.Scatter(\n",
    "    x=final_forecast.index, y=final_forecast.yhat, mode='lines', name='future_prediction', line_color='rgb(0,176,246)'))\n",
    "\n",
    "# update layout\n",
    "fig = fig.update_layout(\n",
    "    width=1000, height=600,\n",
    "    title=dict(text=\"<b>Prophet model train test</b>\",\n",
    "               y=0.9, x=0.5, font_size=18),\n",
    "    xaxis=dict(title=\"<b>Date</b>\", linecolor='black', linewidth=1, ticks=\"outside\",\n",
    "                   rangeslider_visible=True,\n",
    "    rangeselector=dict(\n",
    "        buttons=list(\n",
    "            [dict(count=7, label=\"1w\", step=\"day\",\n",
    "                    stepmode=\"backward\"),\n",
    "                dict(count=1, label=\"1m\", step=\"month\",\n",
    "                    stepmode=\"backward\"),\n",
    "                dict(count=6, label=\"6m\", step=\"month\",\n",
    "                    stepmode=\"backward\"),\n",
    "                dict(count=1, label=\"1y\", step=\"year\",\n",
    "                    stepmode=\"backward\"),\n",
    "                dict(label='full', step=\"all\")\n",
    "                ])\n",
    "    )),\n",
    "    yaxis=dict(title=\"<b>Load demand (in kW)</b>\",\n",
    "               linecolor='black', linewidth=1, ticks=\"outside\"),\n",
    "    font=dict(family=\"Helvetica\", size=12, color=\"black\"),\n",
    "    paper_bgcolor=\"white\")\n",
    "\n",
    "fig = fig.add_shape(\n",
    "        # filled Rectangle\n",
    "            type=\"rect\",\n",
    "            x0=\"2007-08-01\", y0=0,\n",
    "            x1=\"2008-06-22\", y1=3000000,\n",
    "            line=dict(\n",
    "                color=\"black\",\n",
    "                width=1,\n",
    "            ),\n",
    "            fillcolor=\"red\", opacity=0.09, layer=\"below\", line_width=0\n",
    "        )\n",
    "\n",
    "fig.write_html(\"images/\"+col+\"_final_graph\"\".html\")       # write_image for other formats\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternate graph: Final forecast dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set notebook mode to work in offline\n",
    "py.init_notebook_mode()\n",
    "\n",
    "forecast_plot = plot_plotly(model2, forecast2)  # This returns a plotly Figure\n",
    "forecast_plot.write_html(\"images/\"+col+\"_final_graph_2\"\".html\", auto_open=False)\n",
    "forecast_plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component plot for full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display forecast components Prophet.plot_components method\n",
    "# trend, yearly seasonality, and weekly seasonality of the time series\n",
    "# include holiday to see holidays\n",
    "\n",
    "# interactive plots\n",
    "py.init_notebook_mode(connected=False)\n",
    "component_plot = model2.plot_components(forecast2)\n",
    "component_plot.savefig(\"images/\"+col+\"_component_plot_full\"\".pdf\")  # pandas---savefig, write_html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WHAT CAN BE DONE?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Only historical data for energy load has been used. Inclusion of other factor such as temperature will improve the error.**\n",
    "- **Retweak parameters in fbprophet model.**\n",
    "- **Cross Validation**\n",
    "- **Combining multiple forecast**\n",
    "- **Dynamic Time series considering 2008's The Great Recession.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
